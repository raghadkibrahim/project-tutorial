[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI For Lawyers",
    "section": "",
    "text": "Introduction\n\nThis book documents every step of the project so my dad can follow along — from data ingestion to evaluation.\n\n\n\n\n\n\n\nTip\n\n\n\nHow to read this book — The left sidebar lists parts and chapters chronologically. Each chapter shows the latest results; older runs are archived in the Progress appendix.\n\n\n\nProject repo: ?var:book.repo-url\nLatest build: Rendered on each push to main.\n\nThis project builds a legal‑AI stack around Arabic court verdicts. Objectives:\n\nClean and structure raw verdicts (facts, reasoning, verdict, statutes).\nBuild retrieval and analytics pipelines.\nEvaluate embeddings and LLMs for precedent search and drafting.\nShip a transparent, reproducible pipeline.\n\nWe use Python in most chapters; code is baked into the pages, with caches for reproducibility.\n\n\nDataset\nThis dataset contains comprehensive details about all verdicts generated by Dubai Courts judgements. It can be accessed from Dubai Pulse which is the city’s open data portal.\n\n\n\n\n\n\n\n\nVariable\nDescription\nType\n\n\n\n\ncase_subtype_code\nNumber to identify the type of a case\nint\n\n\ncase_year\nNumber reflect the year when the case is raised.\nint\n\n\ncase_serial_number\nNumber reflects the case serial based on the code and year.\nint\n\n\ndecision_number\nNumber to identify the judgment decision.\nint\n\n\njudgment_date\nVerdict date\nDATE\n\n\nrecitals\nJudgment Text\nstring\n\n\ninsertion_date\nInsertion date\nDATE\n\n\nlast_update_date\nlast update date\nDATE",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "project-1.html",
    "href": "project-1.html",
    "title": "Project I - Case Similarity Search Engine",
    "section": "",
    "text": "This part covers locating sources, licensing, schema mapping, and ingestion pipelines.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt",
    "crumbs": [
      "Project I - Case Similarity Search Engine"
    ]
  },
  {
    "objectID": "ch1-1.html",
    "href": "ch1-1.html",
    "title": "Data Preprocessing",
    "section": "",
    "text": "We describe source datasets, provenance, and license constraints.\n\nPrimary dataset: Dubai Court verdicts CSV (≈217k rows).\nLinked lookup: case_subtype_code → subtype labels (external dataset).\n\n\nWe track download URIs and hashes so we can prove provenance.",
    "crumbs": [
      "Project I - Case Similarity Search Engine",
      "Data Preprocessing"
    ]
  },
  {
    "objectID": "ch1-2.html",
    "href": "ch1-2.html",
    "title": "AI For Lawyers",
    "section": "",
    "text": "import pandas as pd\nfrom pathlib import Path\n\np = Path('data/raw/verdicts.csv')\ndf = pd.read_csv(p)\ndf['judgment_date'] = pd.to_datetime(df['judgment_date'], errors='coerce')\ndf['year'] = df['judgment_date'].dt.year\ncounts = df.groupby('year').size().rename('n').reset_index()\ncounts",
    "crumbs": [
      "Project I - Case Similarity Search Engine",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ch1-2.html</span>"
    ]
  },
  {
    "objectID": "project-2.html",
    "href": "project-2.html",
    "title": "PROJECT 2",
    "section": "",
    "text": "We move from clean data → embeddings → retrieval → evaluation.",
    "crumbs": [
      "Part II — Retrieval & Modeling"
    ]
  },
  {
    "objectID": "ch2-1.html",
    "href": "ch2-1.html",
    "title": "2  Chapter 2-1",
    "section": "",
    "text": "import re\nimport pandas as pd\n\n# example cleaner\ndef clean_ar(text):\n    if not isinstance(text, str):\n        return ''\n    text = re.sub(r\"[\\u0617-\\u061A\\u064B-\\u0652]\", \"\", text)  # remove diacritics\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    return text\n\n# apply\n# df['cleaned_recitals'] = df['recitals'].map(clean_ar)",
    "crumbs": [
      "Part II — Retrieval & Modeling",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Text Cleaning & Normalization</span>"
    ]
  },
  {
    "objectID": "ch2-3.html",
    "href": "ch2-3.html",
    "title": "4  Chapter 2 3",
    "section": "",
    "text": "from sentence_transformers import SentenceTransformer\n\nmodel = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n\nembs = model.encode(df['cleaned_recitals'].astype(str).tolist(), batch_size=256, show_progress_bar=True)\n\n# Save to disk for FAISS/ScaNN",
    "crumbs": [
      "Part II — Retrieval & Modeling",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Embeddings & Indexing</span>"
    ]
  },
  {
    "objectID": "ch2-4.html",
    "href": "ch2-4.html",
    "title": "5  Chapter 2.4",
    "section": "",
    "text": "We show prompt templates, red‑teaming, and guardrails for legal use.",
    "crumbs": [
      "Part II — Retrieval & Modeling",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Drafting Assist & Risk Controls</span>"
    ]
  }
]