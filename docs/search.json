[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI For Lawyers",
    "section": "",
    "text": "Introduction\n\nThis guide documents every step of the project from data ingestion to evaluation.\n\n\n\n\n\n\n\nTip\n\n\n\nHow to read this book — The left sidebar lists parts and chapters chronologically. Each chapter shows the latest results; older runs are archived in the Progress appendix.\n\n\n\nProject repo: ?var:book.repo-url\nLatest build: Rendered on each push to main.\n\n\n\nDataset\nThis dataset contains comprehensive details about all verdicts generated by Dubai Courts judgements. It can be accessed from Dubai Pulse which is the city’s open data portal.\n\n\n\n\n\n\n\n\nVariable\nDescription\nType\n\n\n\n\ncase_subtype_code\nNumber to identify the type of a case\nint\n\n\ncase_year\nNumber reflect the year when the case is raised.\nint\n\n\ncase_serial_number\nNumber reflects the case serial based on the code and year.\nint\n\n\ndecision_number\nNumber to identify the judgment decision.\nint\n\n\njudgment_date\nVerdict date\nDATE\n\n\nrecitals\nJudgment Text\nstring\n\n\ninsertion_date\nInsertion date\nDATE\n\n\nlast_update_date\nlast update date\nDATE",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "project-1.html",
    "href": "project-1.html",
    "title": "Project I - Case Similarity Search Engine",
    "section": "",
    "text": "This project builds a legal‑AI stack around Dubai court verdicts.\nObjectives:\n\nClean and structure raw verdicts (facts, reasoning, verdict, statutes).\nBuild retrieval and analytics pipelines.\nEvaluate embeddings and LLMs for precedent search and drafting.\nShip a transparent, reproducible pipeline.\n\nI use Python in most chapters; code is baked into the pages, with caches for reproducibility.",
    "crumbs": [
      "Project I - Case Similarity Search Engine"
    ]
  },
  {
    "objectID": "ch1-1.html",
    "href": "ch1-1.html",
    "title": "1  Explanation",
    "section": "",
    "text": "We describe source datasets, provenance, and license constraints.\n\nPrimary dataset: Dubai Court verdicts CSV (≈217k rows).\nLinked lookup: case_subtype_code → subtype labels (external dataset).\n\n\nWe track download URIs and hashes so we can prove provenance.",
    "crumbs": [
      "Project I - Case Similarity Search Engine",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Explanation</span>"
    ]
  },
  {
    "objectID": "ch1-2.html",
    "href": "ch1-2.html",
    "title": "Data Preprocessing",
    "section": "",
    "text": "Import Libraries\nimport pandas as pd\nfrom pathlib import Path\nfrom datasets import load_dataset\nimport numpy as np\n\n/opt/anaconda3/envs/openai_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm",
    "crumbs": [
      "Project I - Case Similarity Search Engine",
      "Data Preprocessing"
    ]
  },
  {
    "objectID": "ch1-2.html#load-dataset",
    "href": "ch1-2.html#load-dataset",
    "title": "Data Preprocessing",
    "section": "Load Dataset",
    "text": "Load Dataset\n\nverdicts = load_dataset(\n    \"csv\",\n    data_files=\"hf://datasets/raghadkibrahim/dxb_court_data/Verdicts.csv\",\n    streaming=True,\n    split=\"train\",\n)",
    "crumbs": [
      "Project I - Case Similarity Search Engine",
      "Data Preprocessing"
    ]
  },
  {
    "objectID": "ch1-2.html#show-a-sample",
    "href": "ch1-2.html#show-a-sample",
    "title": "Data Preprocessing",
    "section": "Show a sample",
    "text": "Show a sample\n\nimport itertools\n\nsample = list(verdicts.take(5000)) \ndf = pd.DataFrame(sample)\n\ndf.head() \n\n\n\n\n\n\n\n\ncase_subtype_code\ncase_year\ncase_serial_number\ndecision_number\njudgment_date\nrecitals\ninsertion_date\nlast_update_date\n\n\n\n\n0\n1\n1992\n1306\n14\n01-08-2022\nبعد الاطلاع على الأوراق و سماع المرافعة؛؛؛    ...\n01-08-2022\nNone\n\n\n1\n11\n2016\n629\n22\n19-09-2022\nبعد سماع المرافعة الشفوية ومطالعة الاوراق:حيث ...\n19-09-2022\nNone\n\n\n2\n11\n2016\n1005\n18\n25-04-2024\nبعد مطالعة الملف الإلكتروني سماع المرافعة حيث ...\n25-04-2024\nNone\n\n\n3\n11\n2018\n634\n21\n30-05-2022\nبعد سماع المرافعة والاطلاع على الأوراق  : حيث ...\n30-05-2022\nNone\n\n\n4\n11\n2019\n1959\n16\n28-02-2022\nبعد سماع المرافعة ومطالعة الاوراق . حيث ان وقا...\n28-02-2022\nNone",
    "crumbs": [
      "Project I - Case Similarity Search Engine",
      "Data Preprocessing"
    ]
  },
  {
    "objectID": "ch1-2.html#clean-recitals-column",
    "href": "ch1-2.html#clean-recitals-column",
    "title": "Data Preprocessing",
    "section": "Clean recitals Column",
    "text": "Clean recitals Column\nWe will start by ceating a function to clean the text in the recitals column.\n\ndef clean_text(text):\n    text = re.sub(r'\\s+', ' ', text)  # remove extra spaces\n    text = re.sub(r'[^\\w\\s]', '', text)  # remove punctuation\n    return text.strip()\n\nApplying the function:\n\nimport re\n\ndf['cleaned_recitals'] = df['recitals'].apply(clean_text)\n\ndf.head()\n\n\n\n\n\n\n\n\ncase_subtype_code\ncase_year\ncase_serial_number\ndecision_number\njudgment_date\nrecitals\ninsertion_date\nlast_update_date\ncleaned_recitals\n\n\n\n\n0\n1\n1992\n1306\n14\n01-08-2022\nبعد الاطلاع على الأوراق و سماع المرافعة؛؛؛    ...\n01-08-2022\nNone\nبعد الاطلاع على الأوراق و سماع المرافعة وحيث إ...\n\n\n1\n11\n2016\n629\n22\n19-09-2022\nبعد سماع المرافعة الشفوية ومطالعة الاوراق:حيث ...\n19-09-2022\nNone\nبعد سماع المرافعة الشفوية ومطالعة الاوراقحيث ا...\n\n\n2\n11\n2016\n1005\n18\n25-04-2024\nبعد مطالعة الملف الإلكتروني سماع المرافعة حيث ...\n25-04-2024\nNone\nبعد مطالعة الملف الإلكتروني سماع المرافعة حيث ...\n\n\n3\n11\n2018\n634\n21\n30-05-2022\nبعد سماع المرافعة والاطلاع على الأوراق  : حيث ...\n30-05-2022\nNone\nبعد سماع المرافعة والاطلاع على الأوراق حيث إن...\n\n\n4\n11\n2019\n1959\n16\n28-02-2022\nبعد سماع المرافعة ومطالعة الاوراق . حيث ان وقا...\n28-02-2022\nNone\nبعد سماع المرافعة ومطالعة الاوراق حيث ان وقائ...",
    "crumbs": [
      "Project I - Case Similarity Search Engine",
      "Data Preprocessing"
    ]
  },
  {
    "objectID": "ch1-2.html#create-semantic-embeddings",
    "href": "ch1-2.html#create-semantic-embeddings",
    "title": "Data Preprocessing",
    "section": "Create Semantic Embeddings",
    "text": "Create Semantic Embeddings\nEmbeddings turn text into numeric vectors that capture meaning. There are a few options we could choose from, but in this case we shall use sentence_transformer for its excellent multingual abilities.\n\nimport torch\nfrom sentence_transformers import SentenceTransformer\n\ndevice = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n\nmodel = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\nmodel = model.to(device)\n\n\n# Prepare texts \ntexts = df[\"cleaned_recitals\"].astype(str).tolist()\n\n# Encode in chunks to control memory; keep batch_size modest on MPS\nemb_chunks = []\nfor i in range(0, len(texts), 2000):  \n    batch = texts[i:i+2000]\n    embs = model.encode(\n        batch,\n        batch_size=64,                          # 32–128 is usually fine; tweak if you see OOM\n        show_progress_bar=True,\n        convert_to_numpy=True,\n        normalize_embeddings=True         \n    )\n    emb_chunks.append(embs.astype(\"float32\"))   # FAISS prefers float32\nembeddings = np.vstack(emb_chunks)\n\nBatches:   0%|          | 0/32 [00:00&lt;?, ?it/s]Batches:   3%|▎         | 1/32 [00:00&lt;00:18,  1.71it/s]Batches:   6%|▋         | 2/32 [00:00&lt;00:13,  2.28it/s]Batches:   9%|▉         | 3/32 [00:01&lt;00:11,  2.43it/s]Batches:  12%|█▎        | 4/32 [00:01&lt;00:10,  2.67it/s]Batches:  16%|█▌        | 5/32 [00:01&lt;00:10,  2.70it/s]Batches:  19%|█▉        | 6/32 [00:02&lt;00:09,  2.81it/s]Batches:  22%|██▏       | 7/32 [00:02&lt;00:08,  2.97it/s]Batches:  25%|██▌       | 8/32 [00:02&lt;00:07,  3.02it/s]Batches:  28%|██▊       | 9/32 [00:03&lt;00:07,  3.19it/s]Batches:  31%|███▏      | 10/32 [00:03&lt;00:06,  3.31it/s]Batches:  34%|███▍      | 11/32 [00:03&lt;00:06,  3.44it/s]Batches:  38%|███▊      | 12/32 [00:04&lt;00:05,  3.47it/s]Batches:  41%|████      | 13/32 [00:04&lt;00:05,  3.41it/s]Batches:  44%|████▍     | 14/32 [00:04&lt;00:05,  3.46it/s]Batches:  47%|████▋     | 15/32 [00:04&lt;00:04,  3.63it/s]Batches:  50%|█████     | 16/32 [00:05&lt;00:04,  3.75it/s]Batches:  53%|█████▎    | 17/32 [00:05&lt;00:03,  3.79it/s]Batches:  56%|█████▋    | 18/32 [00:05&lt;00:03,  3.90it/s]Batches:  59%|█████▉    | 19/32 [00:05&lt;00:03,  4.02it/s]Batches:  62%|██████▎   | 20/32 [00:06&lt;00:02,  4.14it/s]Batches:  66%|██████▌   | 21/32 [00:06&lt;00:02,  4.22it/s]Batches:  69%|██████▉   | 22/32 [00:06&lt;00:02,  4.30it/s]Batches:  72%|███████▏  | 23/32 [00:06&lt;00:02,  4.38it/s]Batches:  75%|███████▌  | 24/32 [00:06&lt;00:01,  4.44it/s]Batches:  78%|███████▊  | 25/32 [00:07&lt;00:01,  4.51it/s]Batches:  81%|████████▏ | 26/32 [00:07&lt;00:01,  4.58it/s]Batches:  84%|████████▍ | 27/32 [00:07&lt;00:01,  4.64it/s]Batches:  88%|████████▊ | 28/32 [00:07&lt;00:00,  4.49it/s]Batches:  91%|█████████ | 29/32 [00:08&lt;00:00,  4.47it/s]Batches:  94%|█████████▍| 30/32 [00:08&lt;00:00,  4.58it/s]Batches:  97%|█████████▋| 31/32 [00:08&lt;00:00,  4.68it/s]Batches: 100%|██████████| 32/32 [00:08&lt;00:00,  3.75it/s]\nBatches:   0%|          | 0/32 [00:00&lt;?, ?it/s]Batches:   3%|▎         | 1/32 [00:00&lt;00:11,  2.67it/s]Batches:   6%|▋         | 2/32 [00:00&lt;00:10,  2.85it/s]Batches:   9%|▉         | 3/32 [00:01&lt;00:09,  3.01it/s]Batches:  12%|█▎        | 4/32 [00:01&lt;00:08,  3.16it/s]Batches:  16%|█▌        | 5/32 [00:01&lt;00:08,  3.27it/s]Batches:  19%|█▉        | 6/32 [00:01&lt;00:07,  3.36it/s]Batches:  22%|██▏       | 7/32 [00:02&lt;00:07,  3.46it/s]Batches:  25%|██▌       | 8/32 [00:02&lt;00:06,  3.55it/s]Batches:  28%|██▊       | 9/32 [00:02&lt;00:06,  3.61it/s]Batches:  31%|███▏      | 10/32 [00:02&lt;00:06,  3.59it/s]Batches:  34%|███▍      | 11/32 [00:03&lt;00:05,  3.64it/s]Batches:  38%|███▊      | 12/32 [00:03&lt;00:05,  3.70it/s]Batches:  41%|████      | 13/32 [00:03&lt;00:05,  3.78it/s]Batches:  44%|████▍     | 14/32 [00:04&lt;00:04,  3.80it/s]Batches:  47%|████▋     | 15/32 [00:04&lt;00:04,  3.79it/s]Batches:  50%|█████     | 16/32 [00:04&lt;00:04,  3.78it/s]Batches:  53%|█████▎    | 17/32 [00:04&lt;00:03,  3.91it/s]Batches:  56%|█████▋    | 18/32 [00:05&lt;00:03,  4.03it/s]Batches:  59%|█████▉    | 19/32 [00:05&lt;00:03,  4.12it/s]Batches:  62%|██████▎   | 20/32 [00:05&lt;00:02,  4.18it/s]Batches:  66%|██████▌   | 21/32 [00:05&lt;00:02,  4.20it/s]Batches:  69%|██████▉   | 22/32 [00:05&lt;00:02,  4.15it/s]Batches:  72%|███████▏  | 23/32 [00:06&lt;00:02,  4.25it/s]Batches:  75%|███████▌  | 24/32 [00:06&lt;00:01,  4.30it/s]Batches:  78%|███████▊  | 25/32 [00:06&lt;00:01,  4.36it/s]Batches:  81%|████████▏ | 26/32 [00:06&lt;00:01,  4.43it/s]Batches:  84%|████████▍ | 27/32 [00:07&lt;00:01,  4.47it/s]Batches:  88%|████████▊ | 28/32 [00:07&lt;00:00,  4.53it/s]Batches:  91%|█████████ | 29/32 [00:07&lt;00:00,  4.62it/s]Batches:  94%|█████████▍| 30/32 [00:07&lt;00:00,  4.68it/s]Batches:  97%|█████████▋| 31/32 [00:07&lt;00:00,  4.73it/s]Batches: 100%|██████████| 32/32 [00:07&lt;00:00,  4.03it/s]\nBatches:   0%|          | 0/16 [00:00&lt;?, ?it/s]Batches:   6%|▋         | 1/16 [00:00&lt;00:06,  2.25it/s]Batches:  12%|█▎        | 2/16 [00:00&lt;00:05,  2.73it/s]Batches:  19%|█▉        | 3/16 [00:01&lt;00:04,  2.84it/s]Batches:  25%|██▌       | 4/16 [00:01&lt;00:03,  3.02it/s]Batches:  31%|███▏      | 5/16 [00:01&lt;00:03,  3.24it/s]Batches:  38%|███▊      | 6/16 [00:01&lt;00:02,  3.47it/s]Batches:  44%|████▍     | 7/16 [00:02&lt;00:02,  3.61it/s]Batches:  50%|█████     | 8/16 [00:02&lt;00:02,  3.79it/s]Batches:  56%|█████▋    | 9/16 [00:02&lt;00:01,  3.92it/s]Batches:  62%|██████▎   | 10/16 [00:02&lt;00:01,  4.08it/s]Batches:  69%|██████▉   | 11/16 [00:03&lt;00:01,  4.18it/s]Batches:  75%|███████▌  | 12/16 [00:03&lt;00:00,  4.26it/s]Batches:  81%|████████▏ | 13/16 [00:03&lt;00:00,  4.37it/s]Batches:  88%|████████▊ | 14/16 [00:03&lt;00:00,  4.41it/s]Batches:  94%|█████████▍| 15/16 [00:03&lt;00:00,  4.52it/s]Batches: 100%|██████████| 16/16 [00:04&lt;00:00,  4.73it/s]Batches: 100%|██████████| 16/16 [00:04&lt;00:00,  3.86it/s]",
    "crumbs": [
      "Project I - Case Similarity Search Engine",
      "Data Preprocessing"
    ]
  },
  {
    "objectID": "project-2.html",
    "href": "project-2.html",
    "title": "Project II",
    "section": "",
    "text": "We move from clean data → embeddings → retrieval → evaluation.",
    "crumbs": [
      "Project II"
    ]
  },
  {
    "objectID": "ch2-1.html",
    "href": "ch2-1.html",
    "title": "2  Chapter 2-1",
    "section": "",
    "text": "import re\nimport pandas as pd\n\n# example cleaner\ndef clean_ar(text):\n    if not isinstance(text, str):\n        return ''\n    text = re.sub(r\"[\\u0617-\\u061A\\u064B-\\u0652]\", \"\", text)  # remove diacritics\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    return text\n\n# apply\n# df['cleaned_recitals'] = df['recitals'].map(clean_ar)",
    "crumbs": [
      "Project II",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Text Cleaning & Normalization</span>"
    ]
  },
  {
    "objectID": "ch2-4.html",
    "href": "ch2-4.html",
    "title": "5  Chapter 2.4",
    "section": "",
    "text": "We show prompt templates, red‑teaming, and guardrails for legal use.",
    "crumbs": [
      "Project II",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Drafting Assist & Risk Controls</span>"
    ]
  }
]